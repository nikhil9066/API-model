{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input file \n",
    "### check for null\n",
    "### check for preprocessing \n",
    "### standardize\n",
    "### model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipp\n",
    "model_Eval = ipp.pd.DataFrame()\n",
    "ipp.warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ipp.pd.read_csv('/Users/nikhilprao/Documents/Data/Boston.csv', index_col=0)\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# applying the method\n",
    "nan_in_df = df.isnull().sum().any()\n",
    " \n",
    "# Print the dataframe\n",
    "print(type(nan_in_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ask User for predictive column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names to the user\n",
    "print(\"Available predictor variables:\")\n",
    "for idx, col in enumerate(df.columns):\n",
    "    print(f\"{idx + 1}. {col}\")\n",
    "\n",
    "# Ask the user to choose a predictor variable\n",
    "selected_index = int(input(\"Enter the index of the predictor variable you want to choose: \")) - 1\n",
    "\n",
    "# Validate user input\n",
    "if 0 <= selected_index < len(df.columns):\n",
    "    pattern = df.columns[selected_index]\n",
    "    print(f\"Selected predictor variable: {pattern}\")\n",
    "else:\n",
    "    print(\"Invalid index selected. Please choose a valid index.\")\n",
    "\n",
    "\n",
    "predictor_variable = df.filter(regex=f'^{pattern}').columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictor_variable)\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directory to store models\n",
    "# model_dir = \"model_dump\"\n",
    "\n",
    "# # Check if the directory exists\n",
    "# if os.path.exists(model_dir):\n",
    "#     # Check if the directory is not empty\n",
    "#     if os.listdir(model_dir):  # If there are files inside\n",
    "#         # Empty the directory before starting\n",
    "#         for filename in os.listdir(model_dir):\n",
    "#             file_path = os.path.join(model_dir, filename)\n",
    "#             if os.path.isfile(file_path):\n",
    "#                 os.remove(file_path)  # Remove the file\n",
    "#             elif os.path.isdir(file_path):\n",
    "#                 ipp.shutil.rmtree(file_path)  # Remove subdirectory if any\n",
    "# else:\n",
    "#     # If the directory doesn't exist, create it\n",
    "#     os.makedirs(model_dir)\n",
    "\n",
    "# # Now the directory is either empty or newly created\n",
    "# print(f\"Model directory is ready: {model_dir}\")\n",
    "\n",
    "# # # Function to pickle the model and return the file path\n",
    "# # def save_model(model, name):\n",
    "# #     timestamp = ipp.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# #     file_name = f\"{name}_{timestamp}.pkl\"\n",
    "# #     file_path = os.path.join(model_dir, file_name)\n",
    "    \n",
    "# #     with open(file_path, \"wb\") as f:\n",
    "# #         ipp.pickle.dump(model, f)\n",
    "\n",
    "# #     return file_name  # Returning only the file name to store in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil  # For removing subdirectories, if any\n",
    "\n",
    "# json_data to be saved to status.json\n",
    "json_data = {\n",
    "    \"load_data\": {\"csv\": False, \"excel\": False, \"link\": False},\n",
    "    \"pre_processing\": {\"null_handling\": False, \"outliers\": {\"detection\": False, \"removal\": False}},\n",
    "    \"modeling\": {\"model_1\": {\"train\": None, \"test\": None, \"r2_score\": None, \"model\": None}},\n",
    "    \"hyperparameter_tuning\": {\"grid_search\": False, \"random_search\": False},\n",
    "    \"final_checks\": {\"evaluate_performance\": False, \"check_overfitting\": False, \"check_generalization\": False}\n",
    "}\n",
    "\n",
    "# Directory to store models\n",
    "model_dir = \"model_dump\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(model_dir):\n",
    "    # Check if the directory is not empty\n",
    "    if os.listdir(model_dir):  # If there are files inside\n",
    "        # Empty the directory before starting\n",
    "        for filename in os.listdir(model_dir):\n",
    "            file_path = os.path.join(model_dir, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)  # Remove the file\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove subdirectory if any\n",
    "else:\n",
    "    # If the directory doesn't exist, create it\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Now the directory is either empty or newly created\n",
    "print(f\"Model directory is ready: {model_dir}\")\n",
    "\n",
    "# Save the json_data to status.json file\n",
    "json_file_path = os.path.join(model_dir, \"status.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipp.interModel(df, predictor_variable, \"Linear_Regression_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
